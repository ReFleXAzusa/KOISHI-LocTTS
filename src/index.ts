// plugins/loctts/index.ts
import { Context, Schema, h, Session } from 'koishi'
import axios from 'axios'
import { createWriteStream } from 'fs'
import { join } from 'path'
import { existsSync, mkdirSync } from 'fs'

export const name = 'loctts'

// å®šä¹‰ cutMethod çš„è”åˆç±»å‹
type CutMethod = 'cut0' | 'cut1' | 'cut2' | 'cut3' | 'cut4' | 'cut5'

export interface Config {
  apiBase: string
  referWavPath: string
  promptText: string
  promptLanguage: string
  textLanguage: string
  autoConvert: boolean
  cutMethod: CutMethod
  filterBrackets: boolean
  filterEmojis: boolean
  gptModelPath: string
  sovitsModelPath: string
}

export const Config: Schema<Config> = Schema.object({
  apiBase: Schema.string().description('GSVæ¨ç†WEBUIåœ°å€').default('http://localhost:9880'),
  referWavPath: Schema.string().description('å‚è€ƒéŸ³é¢‘è·¯å¾„').required(),
  promptText: Schema.string().description('å‚è€ƒæ–‡æœ¬').default(''),
  promptLanguage: Schema.string().description('å‚è€ƒæ–‡æœ¬è¯­è¨€').default('zh'),
  textLanguage: Schema.string().description('ç›®æ ‡æ–‡æœ¬è¯­è¨€').default('zh'),
  autoConvert: Schema.boolean().description('è‡ªåŠ¨è½¬æ¢AIå›å¤ä¸ºè¯­éŸ³').default(false),
  cutMethod: Schema.union([
    Schema.const('cut0' as const).description('ä¸åˆ‡'),
    Schema.const('cut1' as const).description('å‡‘å››å¥ä¸€åˆ‡'),
    Schema.const('cut2' as const).description('æŒ‰æ ‡ç‚¹ç¬¦å·åˆ‡'),
    Schema.const('cut3' as const).description('æŒ‰å­—åˆ‡'),
    Schema.const('cut4' as const).description('æŒ‰æ¢è¡Œåˆ‡'),
    Schema.const('cut5' as const).description('æŒ‰å¥å­åˆ‡')
  ]).description('æ–‡æœ¬åˆ‡å‰²æ–¹æ³•').default('cut5' as CutMethod),
  filterBrackets: Schema.boolean().description('è¿‡æ»¤æ‹¬å·å†…å®¹').default(true),
  filterEmojis: Schema.boolean().description('è¿‡æ»¤è¡¨æƒ…ç¬¦å·').default(true),
  gptModelPath: Schema.string().description('GPTæ¨¡å‹è·¯å¾„ (.pthæ–‡ä»¶)').default(''),
  sovitsModelPath: Schema.string().description('SoVITSæ¨¡å‹è·¯å¾„ (.pthæ–‡ä»¶)').default(''),
})

export function apply(ctx: Context, config: Config) {
  // åˆ›å»ºä¸´æ—¶ç›®å½•
  const tempDir = join(__dirname, '../temp')
  if (!existsSync(tempDir)) {
    mkdirSync(tempDir, { recursive: true })
  }

  // æ¨¡å‹ç®¡ç†å‡½æ•°
  async function loadModels() {
    if (config.gptModelPath && existsSync(config.gptModelPath)) {
      try {
        await axios.get(`${config.apiBase}/set_gpt_weights`, {
          params: { weights_path: config.gptModelPath },
          timeout: 30000
        })
        ctx.logger.info(`GPTæ¨¡å‹åŠ è½½æˆåŠŸ: ${config.gptModelPath}`)
      } catch (error: any) {
        ctx.logger.error(`GPTæ¨¡å‹åŠ è½½å¤±è´¥: ${error.message}`)
      }
    }

    if (config.sovitsModelPath && existsSync(config.sovitsModelPath)) {
      try {
        await axios.get(`${config.apiBase}/set_sovits_weights`, {
          params: { weights_path: config.sovitsModelPath },
          timeout: 30000
        })
        ctx.logger.info(`SoVITSæ¨¡å‹åŠ è½½æˆåŠŸ: ${config.sovitsModelPath}`)
      } catch (error: any) {
        ctx.logger.error(`SoVITSæ¨¡å‹åŠ è½½å¤±è´¥: ${error.message}`)
      }
    }
  }

  // æ’ä»¶å¯åŠ¨æ—¶åŠ è½½æ¨¡å‹
  ctx.on('ready', async () => {
    await loadModels()
  })

  // æ–‡æœ¬é¢„å¤„ç†å‡½æ•°ï¼ˆåŒ…å«æ‹¬å·è¿‡æ»¤ï¼‰
  function preprocessText(text: string, config: Config): string {
    let processedText = text;
    
    // æ ¹æ®é…ç½®è¿‡æ»¤æ‹¬å·å†…å®¹
    if (config.filterBrackets) {
      processedText = processedText
        .replace(/\([^)]*\)/g, '')
        .replace(/ï¼ˆ[^ï¼‰]*ï¼‰/g, '')
        .replace(/\[[^\]]*\]/g, '')
        .replace(/ã€[^ã€‘]*ã€‘/g, '')
        .replace(/\{[^}]*\}/g, '')
        .replace(/<[^>]*>/g, '')
        .replace(/ã€Š[^ã€‹]*ã€‹/g, '');
    }
    
    // æ ¹æ®é…ç½®è¿‡æ»¤è¡¨æƒ…ç¬¦å·
    if (config.filterEmojis) {
      processedText = processedText
        .replace(/[\u{1F600}-\u{1F64F}]/gu, '')
        .replace(/[\u{1F300}-\u{1F5FF}]/gu, '')
        .replace(/[\u{1F680}-\u{1F6FF}]/gu, '')
        .replace(/[\u{1F700}-\u{1F77F}]/gu, '')
        .replace(/[\u{1F780}-\u{1F7FF}]/gu, '')
        .replace(/[\u{1F800}-\u{1F8FF}]/gu, '')
        .replace(/[\u{1F900}-\u{1F9FF}]/gu, '')
        .replace(/[\u{2600}-\u{26FF}]/gu, '')
        .replace(/[\u{2700}-\u{27BF}]/gu, '');
    }
    
    // å…¶ä»–é¢„å¤„ç†
    processedText = processedText
      .replace(/[#*_~`|]/g, '')
      .replace(/(http[s]?:\/\/[^\s]+)/g, 'é“¾æ¥')
      .replace(/@(\w+)/g, 'ç”¨æˆ·$1')
      .replace(/\s+/g, ' ')
      .replace(/ï¼Œ\s*ï¼Œ/g, 'ï¼Œ')
      .replace(/ã€‚\s*ã€‚/g, 'ã€‚')
      .replace(/ï¼\s*ï¼/g, 'ï¼')
      .replace(/ï¼Ÿ\s*ï¼Ÿ/g, 'ï¼Ÿ')
      .trim();

    if (processedText.length === 0) {
      processedText = 'æ— æœ‰æ•ˆæ–‡æœ¬å†…å®¹';
    }

    return processedText;
  }

  // æ ¸å¿ƒè½¬æ¢å‡½æ•°
  async function convertTextToSpeech(text: string, config: Config): Promise<string> {
    // æ–‡æœ¬é¢„å¤„ç†ï¼Œä¼ å…¥ config
    const processedText = preprocessText(text, config)
    
    try {
      // æ ¹æ® API v2 æ–‡æ¡£æ„å»ºè¯·æ±‚æ•°æ®
      const requestData = {
        text: processedText,
        text_lang: config.textLanguage.toLowerCase(),
        ref_audio_path: config.referWavPath,
        prompt_text: config.promptText,
        prompt_lang: config.promptLanguage.toLowerCase(),
        text_split_method: config.cutMethod,
        top_k: 5,
        top_p: 1,
        temperature: 1,
        batch_size: 1,
        batch_threshold: 0.75,
        split_bucket: true,
        speed_factor: 1.0,
        seed: -1,
        media_type: "wav",
        streaming_mode: false,
        parallel_infer: true,
        repetition_penalty: 1.35,
        sample_steps: 32,
        super_sampling: false
      }

      ctx.logger.info('å‘é€ TTS è¯·æ±‚åˆ°:', `${config.apiBase}/tts`)
      
      const response = await axios({
        method: 'post',
        url: `${config.apiBase}/tts`,
        headers: {
          'Content-Type': 'application/json',
        },
        data: requestData,
        responseType: 'stream',
        timeout: 60000
      })

      // ä¿å­˜éŸ³é¢‘æ–‡ä»¶
      const outputFile = join(tempDir, `tts_${Date.now()}.wav`)
      const writer = createWriteStream(outputFile)
      
      response.data.pipe(writer)
      
      return new Promise((resolve, reject) => {
        writer.on('finish', () => {
          ctx.logger.info(`è¯­éŸ³ç”ŸæˆæˆåŠŸ: ${outputFile}`)
          resolve(outputFile)
        })
        writer.on('error', (error) => {
          ctx.logger.error('ä¿å­˜éŸ³é¢‘æ–‡ä»¶å¤±è´¥:', error)
          reject(error)
        })
      })
      
    } catch (error: any) {
      if (error.response) {
        let errorDetails = ''
        try {
          if (error.response.data && typeof error.response.data.on === 'function') {
            const data = await new Promise<string>((resolve) => {
              let chunks = ''
              error.response.data.on('data', (chunk: Buffer) => chunks += chunk.toString())
              error.response.data.on('end', () => resolve(chunks))
            })
            errorDetails = ` - ${data}`
          } else {
            errorDetails = ` - ${error.response.data}`
          }
        } catch (e) {
          errorDetails = ' - æ— æ³•è¯»å–é”™è¯¯è¯¦æƒ…'
        }
        
        throw new Error(`GSV API é”™è¯¯: ${error.response.status}${errorDetails}`)
      } else if (error.code === 'ECONNREFUSED') {
        throw new Error(`æ— æ³•è¿æ¥åˆ° GSV æœåŠ¡ (${config.apiBase})ã€‚è¯·ç¡®è®¤ GPT-SOVITS æœåŠ¡å·²å¯åŠ¨`)
      } else {
        throw new Error(`è¯·æ±‚å¤±è´¥: ${error.message}`)
      }
    }
  }

  // æ³¨å†Œ TTS å‘½ä»¤
  ctx.command('tts <text:string>', 'æ–‡æœ¬è½¬è¯­éŸ³')
    .action(async ({ session }, text) => {
      if (!text) return 'è¯·è¾“å…¥è¦è½¬æ¢çš„æ–‡æœ¬'
      
      try {
        const audioFile = await convertTextToSpeech(text, config)
        return h.audio(`file:///${audioFile}`)
      } catch (error: any) {
        ctx.logger.error('TTS è½¬æ¢å¤±è´¥:', error)
        return `è¯­éŸ³è½¬æ¢å¤±è´¥: ${error.message}`
      }
    })

  // æ¨¡å‹ç®¡ç†å‘½ä»¤
  ctx.command('tts.model <action:string>', 'æ¨¡å‹ç®¡ç†')
    .option('gpt', '-g <model>')
    .option('sovits', '-s <model>')
    .action(async ({ session, options }, action) => {
      try {
        switch (action) {
          case 'load':
            await loadModels()
            return 'æ¨¡å‹é‡æ–°åŠ è½½å®Œæˆ'
            
          case 'setgpt':
            if (!options.gpt) return 'è¯·æä¾›GPTæ¨¡å‹è·¯å¾„ï¼Œä½¿ç”¨ -g å‚æ•°'
            if (!existsSync(options.gpt)) return `æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: ${options.gpt}`
            
            await axios.get(`${config.apiBase}/set_gpt_weights`, {
              params: { weights_path: options.gpt },
              timeout: 30000
            })
            config.gptModelPath = options.gpt
            return `GPTæ¨¡å‹å·²è®¾ç½®ä¸º: ${options.gpt}`
            
          case 'setsovits':
            if (!options.sovits) return 'è¯·æä¾›SoVITSæ¨¡å‹è·¯å¾„ï¼Œä½¿ç”¨ -s å‚æ•°'
            if (!existsSync(options.sovits)) return `æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: ${options.sovits}`
            
            await axios.get(`${config.apiBase}/set_sovits_weights`, {
              params: { weights_path: options.sovits },
              timeout: 30000
            })
            config.sovitsModelPath = options.sovits
            return `SoVITSæ¨¡å‹å·²è®¾ç½®ä¸º: ${options.sovits}`
            
          case 'status':
            const status = []
            if (config.gptModelPath) {
              status.push(`GPTæ¨¡å‹: ${config.gptModelPath}`)
            } else {
              status.push('GPTæ¨¡å‹: æœªè®¾ç½®')
            }
            if (config.sovitsModelPath) {
              status.push(`SoVITSæ¨¡å‹: ${config.sovitsModelPath}`)
            } else {
              status.push('SoVITSæ¨¡å‹: æœªè®¾ç½®')
            }
            return status.join('\n')
            
          default:
            return 'å¯ç”¨æ“ä½œ: load, setgpt, setsovits, status\nä½¿ç”¨ç¤ºä¾‹: /tts.model setgpt -g /path/to/model.pth'
        }
      } catch (error: any) {
        return `æ¨¡å‹æ“ä½œå¤±è´¥: ${error.message}`
      }
    })

  // æ”¹è¿›çš„è‡ªåŠ¨è½¬æ¢ä¸­é—´ä»¶ - é€šç”¨æ–¹æ¡ˆ
  if (config.autoConvert) {
    let isProcessing = false // é˜²æ­¢é‡å¤å¤„ç†
    
    // æ”¹è¿›çš„é€šç”¨æ–‡æœ¬æå–å‡½æ•°
    function extractReplyText(content: any): string {
      if (!content) return ''
      
      // å­—ç¬¦ä¸²ç›´æ¥è¿”å›
      if (typeof content === 'string') {
        return content
      }
      
      // æ¶ˆæ¯å…ƒç´ æ•°ç»„
      if (Array.isArray(content)) {
        return content
          .map(item => {
            if (typeof item === 'string') return item
            // å¤„ç†å„ç§æ¶ˆæ¯å…ƒç´ 
            if (item?.type === 'text') return item.attrs?.content || ''
            if (item?.attrs?.content) return item.attrs.content
            if (item?.attrs?.url && !item.attrs.url.match(/\.(jpg|jpeg|png|gif|bmp)$/i)) {
              return '[åª’ä½“å†…å®¹]'
            }
            return ''
          })
          .filter(text => text.trim().length > 0)
          .join(' ')
      }
      
      // å•ä¸ªæ¶ˆæ¯å…ƒç´ 
      if (content?.type === 'text' && content.attrs?.content) {
        return content.attrs.content
      }
      
      // å¯¹è±¡ç±»å‹ï¼Œå°è¯•è½¬æ¢ä¸ºå­—ç¬¦ä¸²
      if (typeof content === 'object') {
        try {
          return JSON.stringify(content).replace(/[{}"\\]/g, ' ')
        } catch {
          return '[å¯¹è±¡å†…å®¹]'
        }
      }
      
      return String(content || '')
    }
    
    // æ”¹è¿›çš„æ–‡æœ¬æœ‰æ•ˆæ€§æ£€æŸ¥
    function isValidForTTS(text: string): boolean {
      if (!text || text.trim().length < 2) return false
      
      const trimmedText = text.trim()
      
      // è·³è¿‡çº¯ç¬¦å·ã€é“¾æ¥ã€å‘½ä»¤ç­‰
      const skipPatterns = [
        /^[!@#$%^&*()_+\-=\[\]{};':"\\|,.<>\/?~\s]*$/, // çº¯ç¬¦å·
        /^https?:\/\//, // é“¾æ¥
        /^\/\w+/, // å‘½ä»¤
        /^(ok|å—¯|å•Š|å“¦|å‘µå‘µ|å“ˆå“ˆ)$/i, // ç®€å•å›å¤
        /^\[.*\]$/, // æ–¹æ‹¬å·å†…å®¹
        /^[\u4e00-\u9fa5]{1,2}$/, // å•ä¸ªä¸­æ–‡å­—ç¬¦
      ]
      
      return !skipPatterns.some(pattern => pattern.test(trimmedText))
    }
    
    // ç‹¬ç«‹çš„è¯­éŸ³å¤„ç†å‡½æ•°
    async function processAudioConversion(session: Session, result: any) {
      try {
        // æ”¹è¿›çš„é€šç”¨æ–‡æœ¬æå–
        const textContent = extractReplyText(result)
        
        if (isValidForTTS(textContent)) {
          ctx.logger.info(`è‡ªåŠ¨TTSè½¬æ¢: ${textContent.substring(0, 50)}...`)
          
          const audioFile = await convertTextToSpeech(textContent, config)
          // å»¶è¿Ÿå‘é€è¯­éŸ³ï¼Œç¡®ä¿æ–‡æœ¬å…ˆæ˜¾ç¤º
          setTimeout(() => {
            session.send(h.audio(`file:///${audioFile}`)).catch(error => {
              ctx.logger.error('å‘é€è¯­éŸ³æ¶ˆæ¯å¤±è´¥:', error)
            })
          }, 1000)
        }
      } catch (error: any) {
        ctx.logger.error('è‡ªåŠ¨TTSè½¬æ¢å¤±è´¥:', error)
      }
    }
    
    ctx.middleware(async (session: Session, next) => {
      // å…ˆæ‰§è¡Œåç»­ä¸­é—´ä»¶è·å–å›å¤
      const result = await next()
      
      // è·³è¿‡æ¡ä»¶
      if (!result || 
          session.content.startsWith('/tts') || 
          session.content.startsWith('tts.') ||
          isProcessing) {
        return result
      }
      
      // æ ‡è®°ä¸ºå¤„ç†ä¸­ï¼Œé˜²æ­¢é‡å¤
      isProcessing = true
      
      // å¼‚æ­¥å¤„ç†è¯­éŸ³è½¬æ¢ï¼Œä¸é˜»å¡åŸå§‹å›å¤
      processAudioConversion(session, result).catch(error => {
        ctx.logger.error('è‡ªåŠ¨TTSå¤„ç†å¤±è´¥:', error)
      }).finally(() => {
        isProcessing = false
      })
      
      return result
    })
  }

  // æ·»åŠ è°ƒè¯•å‘½ä»¤æ¥æŸ¥çœ‹è¿‡æ»¤æ•ˆæœ
  ctx.command('tts.filter <text:string>', 'æµ‹è¯•æ–‡æœ¬è¿‡æ»¤æ•ˆæœ')
    .action(async ({ session }, text) => {
      if (!text) return 'è¯·è¾“å…¥è¦æµ‹è¯•çš„æ–‡æœ¬'
      
      const originalText = text
      const filteredText = preprocessText(text, config)
      
      return `è¿‡æ»¤å‰: ${originalText}\nè¿‡æ»¤å: ${filteredText}`
    })

  // æ·»åŠ å‘½ä»¤æ¥ä¸´æ—¶å…³é—­è¿‡æ»¤
  ctx.command('tts.raw <text:string>', 'ä¸ç»è¿‡æ»¤ç›´æ¥è½¬æ¢æ–‡æœ¬')
    .action(async ({ session }, text) => {
      if (!text) return 'è¯·è¾“å…¥è¦è½¬æ¢çš„æ–‡æœ¬'
      
      try {
        // ä¸´æ—¶åˆ›å»ºä¸€ä¸ªä¸è¿‡æ»¤çš„é…ç½®
        const tempConfig = { ...config }
        tempConfig.filterBrackets = false
        tempConfig.filterEmojis = false
        
        const audioFile = await convertTextToSpeech(text, tempConfig)
        return [
          h.text(`åŸå§‹æ–‡æœ¬: ${text}`),
          h.audio(`file:///${audioFile}`)
        ]
      } catch (error: any) {
        return `è¯­éŸ³è½¬æ¢å¤±è´¥: ${error.message}`
      }
    })

  // æœåŠ¡çŠ¶æ€æ£€æŸ¥
  ctx.command('tts.check', 'æ£€æŸ¥ GSV æœåŠ¡çŠ¶æ€')
    .action(async () => {
      try {
        // ç›´æ¥æµ‹è¯• /tts ç«¯ç‚¹
        const testData = {
          text: "æµ‹è¯•",
          text_lang: "zh",
          ref_audio_path: config.referWavPath,
          prompt_text: "æµ‹è¯•",
          prompt_lang: "zh",
          text_split_method: "cut5"
        }
        
        const response = await axios.post(`${config.apiBase}/tts`, testData, {
          timeout: 10000,
          validateStatus: () => true
        })
        
        if (response.status === 200) {
          return `âœ… GSV æœåŠ¡è¿è¡Œæ­£å¸¸ (${config.apiBase})`
        } else {
          return `âŒ GSV æœåŠ¡è¿”å›é”™è¯¯: ${response.status}`
        }
      } catch (error: any) {
        if (error.code === 'ECONNREFUSED') {
          return `âŒ æ— æ³•è¿æ¥åˆ° GSV æœåŠ¡ (${config.apiBase})`
        } else {
          return `âŒ è¿æ¥å¤±è´¥: ${error.message}`
        }
      }
    })

  // é€šç”¨é›†æˆæµ‹è¯•å‘½ä»¤ï¼ˆä¿®å¤ç‰ˆæœ¬ï¼‰
  ctx.command('tts.integration <message:text>', 'æµ‹è¯•TTSä¸AIé›†æˆ')
    .action(async ({ session }, message) => {
      if (!message) return 'è¯·è¾“å…¥æµ‹è¯•æ¶ˆæ¯'
      
      try {
        // æ­¥éª¤1: æ˜¾ç¤ºåŸå§‹æ¶ˆæ¯
        await session.send(`æµ‹è¯•æ¶ˆæ¯: ${message}`)
        
        // æ­¥éª¤2: å°è¯•è·å–AIå›å¤ï¼ˆå¦‚æœæœ‰AIæ’ä»¶ï¼‰- ä½¿ç”¨æ›´é€šç”¨çš„æ–¹å¼
        let aiReply = null
        try {
          // æ–¹æ³•1: å°è¯•é€šè¿‡ä¸­é—´ä»¶è·å–AIå›å¤
          // è¿™é‡Œæˆ‘ä»¬æ¨¡æ‹Ÿä¸€ä¸ªAIå›å¤ï¼Œå› ä¸ºæ— æ³•ç›´æ¥è®¿é—®AIæœåŠ¡
          aiReply = `è¿™æ˜¯å¯¹"${message}"çš„æµ‹è¯•å›å¤ã€‚å½“å‰æ—¶é—´: ${new Date().toLocaleTimeString()}`
          
          // å¦‚æœæœ‰å…¶ä»–æ–¹å¼è°ƒç”¨AIï¼Œå¯ä»¥åœ¨è¿™é‡Œæ·»åŠ 
          // ä¾‹å¦‚é€šè¿‡æ‰§è¡Œå‘½ä»¤çš„æ–¹å¼
          // const result = await session.execute(`/ai ${message}`)
          // if (result) aiReply = result
          
        } catch (error) {
          aiReply = `AIæœåŠ¡æš‚ä¸å¯ç”¨ï¼Œä½¿ç”¨æµ‹è¯•å›å¤: ${message}çš„æµ‹è¯•è¯­éŸ³`
        }
        
        await session.send(`AIå›å¤: ${aiReply}`)
        
        // æ­¥éª¤3: è½¬æ¢ä¸ºè¯­éŸ³
        const audioFile = await convertTextToSpeech(aiReply, config)
        await session.send(h.audio(`file:///${audioFile}`))
        
        return 'é›†æˆæµ‹è¯•å®Œæˆ'
      } catch (error: any) {
        return `é›†æˆæµ‹è¯•å¤±è´¥: ${error.message}`
      }
    })

  // çŠ¶æ€æ£€æŸ¥å‘½ä»¤ï¼ˆä¿®å¤ç‰ˆæœ¬ï¼‰
  ctx.command('tts.status', 'æ£€æŸ¥TTSæ’ä»¶çŠ¶æ€')
    .action(async () => {
      const status = [
        `âœ… TTSæœåŠ¡: ${config.apiBase}`,
        `ğŸ¯ è‡ªåŠ¨è½¬æ¢: ${config.autoConvert ? 'å¼€å¯' : 'å…³é—­'}`,
        `ğŸ”Š å‚è€ƒéŸ³é¢‘: ${config.referWavPath}`,
        `ğŸ“ æ–‡æœ¬è¿‡æ»¤: æ‹¬å·${config.filterBrackets ? 'å¼€' : 'å…³'}, è¡¨æƒ…${config.filterEmojis ? 'å¼€' : 'å…³'}`,
        `âœ‚ï¸ åˆ‡å‰²æ–¹æ³•: ${config.cutMethod}`,
      ]
      
      // æ£€æŸ¥AIæœåŠ¡çŠ¶æ€ - ä½¿ç”¨æ›´é€šç”¨çš„æ–¹å¼
      try {
        // å°è¯•æ£€æµ‹æ˜¯å¦æœ‰AIæœåŠ¡å¯ç”¨
        // è¿™é‡Œä½¿ç”¨æ›´ä¿å®ˆçš„æ£€æµ‹æ–¹æ³•
        const hasAIService = ctx.get('satori') !== undefined
        if (hasAIService) {
          status.push('âœ… AIæœåŠ¡: æ£€æµ‹åˆ°å¯èƒ½çš„AIæœåŠ¡')
        } else {
          status.push('âŒ AIæœåŠ¡: æœªæ£€æµ‹åˆ°AIæœåŠ¡')
        }
      } catch {
        status.push('â“ AIæœåŠ¡: çŠ¶æ€æœªçŸ¥')
      }
      
      return status.join('\n')
    })
}